{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loads and preprocesses NCAA data from http://www.cfbstats.com/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import zipfile\n",
      "import pandas as pd\n",
      "import string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_team_alignment():\n",
      "    '''Reads in teams and conferences datasets for current alignment and joins'''\n",
      "    archive = zipfile.ZipFile('data/cfbstats.com-2013-1.5.20.zip', 'r')\n",
      "    teams = pd.read_csv(archive.extract('team.csv'), header=0, names=['Team Code', 'college', 'conf_code'])\n",
      "    confs = pd.read_csv(archive.extract('conference.csv'), header=0, names=['conf_code', 'conference', 'subn'])\n",
      "    teams_plus = pd.merge(teams, confs)\n",
      "    return teams_plus.drop('conf_code', axis=1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_stats_and_players():\n",
      "    '''Reads in NCAA player stats and game stats and concatenates seasons 2005-2013.\n",
      "    Returns a players dataframe and a stats dataframe'''\n",
      "    \n",
      "    table = string.maketrans(\"\",\"\")\n",
      "    \n",
      "    all_players = pd.DataFrame()\n",
      "    all_stats = pd.DataFrame()\n",
      "    # goes through all years of data and concatenates seasons together row-wise for players and games\n",
      "    for yearspan in ['2013-1.5.20', '2012-1.5.4', '2011-1.5.0', '2010-1.5.0',\n",
      "        '2009-1.5.0', '2008-1.5.0', '2007-1.5.0', '2006-1.5.0', '2005-1.5.0']:\n",
      "        archive = zipfile.ZipFile('data/cfbstats.com-'+str(yearspan)+'.zip', 'r')\n",
      "        players = pd.read_csv(archive.extract('player.csv'), header=0)\n",
      "        players['ncaa_season'] = string.split(yearspan, '-')[0]\n",
      "        print yearspan, players.shape\n",
      "        all_players = pd.concat((all_players, players), ignore_index=True)\n",
      "        \n",
      "        player_stats = pd.read_csv(archive.extract('player-game-statistics.csv'), header=0)\n",
      "        player_stats['ncaa_season'] = string.split(yearspan, '-')[0]\n",
      "        print yearspan, player_stats.shape\n",
      "        all_stats = pd.concat((all_stats, player_stats), ignore_index=True)\n",
      "    \n",
      "    # standardizes names    \n",
      "    all_players['first_name'] = [str(d).lower().translate(table, string.punctuation).strip()\\\n",
      "    for d in all_players['First Name']]\n",
      "    all_players['last_name'] = [str(d).lower().translate(table, string.punctuation).strip()\\\n",
      "    for d in all_players['Last Name']]\n",
      "    # rearrange columns to put standardized name and season to front of dataframe\n",
      "    cols = all_players.columns.tolist()\n",
      "    cols = cols[-3:] + cols[:-3]\n",
      "    all_players = all_players[cols].drop('Last Name', axis=1).drop('First Name', axis=1)\n",
      "    return all_players, all_stats\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def aggregate_stats():\n",
      "    '''Builds out NCAA teams, players, and stats dataframes\n",
      "    Groups players and game stats dataframes by player code and takes only their final season\n",
      "    Returns a dataframe aggregated by player, and writes df to csv'''\n",
      "    \n",
      "    # build team alignment, players, and games dataframes\n",
      "    teams_plus = build_team_alignment()\n",
      "    all_players, all_stats = build_stats_and_players()\n",
      "    print 'built dataframes'\n",
      "    \n",
      "    #  group players by player selecting only final season\n",
      "    all_players_by = all_players.groupby(['Player Code']).apply(lambda t: t[t.ncaa_season==t.ncaa_season.max()])\n",
      "    all_players_by['Player Code'] = [d[0] for d in all_players_by.index]\n",
      "    print 'grouped players'\n",
      "    \n",
      "    # aggregating stats using sums; groups by player and grabs all rows for their max ncaa season, then aggregates\n",
      "    all_stats_by = all_stats.groupby(['Player Code']).apply(lambda t: t[t.ncaa_season==t.ncaa_season.max()])\n",
      "    all_stats_sum = all_stats_by.groupby(['Player Code', 'ncaa_season']).sum()\n",
      "    all_stats_sum['Player Code'] = [d[0] for d in all_stats_sum.index]\n",
      "    all_stats_sum['ncaa_season'] = [d[1] for d in all_stats_sum.index]\n",
      "    \n",
      "    # stats aggregating using means\n",
      "    all_stats_mean = all_stats_by.groupby(['Player Code', 'ncaa_season']).mean()\n",
      "    all_stats_mean['Player Code'] = [d[0] for d in all_stats_mean.index]\n",
      "    all_stats_mean['ncaa_season'] = [d[1] for d in all_stats_mean.index]\n",
      "    print 'aggregated stats'\n",
      "    \n",
      "    # merge sum and mean stats and then merge with players\n",
      "    all_stats = pd.merge(all_stats_sum, all_stats_mean, on=['Player Code', 'ncaa_season'], \n",
      "                         suffixes=['_sum', '_mean'])\n",
      "    all_ncaa = pd.merge(all_players_by, all_stats, how='right', on='Player Code', suffixes=['_player', '_stats'])\n",
      "    all_ncaa = pd.merge(all_ncaa, teams_plus, on='Team Code', how='left')\n",
      "    \n",
      "    # reorder columns\n",
      "    col_order = ['ncaa_season_player', 'first_name', 'last_name', 'Class', 'Height', 'Weight', \n",
      "     'Home Country', 'Home State', 'Home Town', 'Last School', 'Player Code', \n",
      "     'Position', 'Team Code', 'Uniform Number', 'college', 'conference', 'subn', 'ncaa_season_stats', \n",
      "     \n",
      "     'Def 2XP Att_sum', 'Def 2XP Made_sum', 'Field Goal Att_sum', 'Field Goal Made_sum', \n",
      "     'Fum Ret_sum', 'Fum Ret TD_sum', 'Fum Ret Yard_sum', 'Fumble_sum', \n",
      "     'Fumble Forced_sum', 'Fumble Lost_sum', 'Game Code_sum', 'Int Ret_sum', 'Int Ret TD_sum', \n",
      "     'Int Ret Yard_sum', 'Kick/Punt Blocked_sum', 'Kickoff_sum', 'Kickoff Onside_sum', \n",
      "     'Kickoff Out-Of-Bounds_sum', 'Kickoff Ret_sum', 'Kickoff Ret TD_sum', 'Kickoff Ret Yard_sum', \n",
      "     'Kickoff Touchback_sum', 'Kickoff Yard_sum', 'Misc Ret_sum', 'Misc Ret TD_sum', 'Misc Ret Yard_sum', \n",
      "     'Off 2XP Att_sum', 'Off 2XP Made_sum', 'Off XP Kick Att_sum', 'Off XP Kick Made_sum', \n",
      "     'Pass Att_sum', 'Pass Broken Up_sum', 'Pass Comp_sum', 'Pass Conv_sum', 'Pass Int_sum', \n",
      "     'Pass TD_sum', 'Pass Yard_sum', 'Points_sum', 'Punt_sum', 'Punt Ret_sum', \n",
      "     'Punt Ret TD_sum', 'Punt Ret Yard_sum', 'Punt Yard_sum', 'QB Hurry_sum', \n",
      "     'Rec_sum', 'Rec TD_sum', 'Rec Yards_sum', 'Rush Att_sum', 'Rush TD_sum', 'Rush Yard_sum', \n",
      "     'Sack_sum', 'Sack Yard_sum', 'Safety_sum', 'Tackle Assist_sum', 'Tackle For Loss_sum', \n",
      "     'Tackle For Loss Yard_sum', 'Tackle Solo_sum', \n",
      "     \n",
      "     'Def 2XP Att_mean', 'Def 2XP Made_mean', 'Field Goal Att_mean', 'Field Goal Made_mean', \n",
      "     'Fum Ret_mean', 'Fum Ret TD_mean', 'Fum Ret Yard_mean', 'Fumble_mean', \n",
      "     'Fumble Forced_mean', 'Fumble Lost_mean', 'Game Code_mean', 'Int Ret_mean', 'Int Ret TD_mean', \n",
      "     'Int Ret Yard_mean', 'Kick/Punt Blocked_mean', 'Kickoff_mean', 'Kickoff Onside_mean', \n",
      "     'Kickoff Out-Of-Bounds_mean', 'Kickoff Ret_mean', 'Kickoff Ret TD_mean', 'Kickoff Ret Yard_mean',\n",
      "     'Kickoff Touchback_mean', 'Kickoff Yard_mean', 'Misc Ret_mean', 'Misc Ret TD_mean', 'Misc Ret Yard_mean',\n",
      "     'Off 2XP Att_mean', 'Off 2XP Made_mean', 'Off XP Kick Att_mean', 'Off XP Kick Made_mean', \n",
      "     'Pass Att_mean', 'Pass Broken Up_mean', 'Pass Comp_mean', 'Pass Conv_mean', 'Pass Int_mean', \n",
      "     'Pass TD_mean', 'Pass Yard_mean', 'Points_mean', 'Punt_mean', 'Punt Ret_mean', \n",
      "     'Punt Ret TD_mean', 'Punt Ret Yard_mean', 'Punt Yard_mean', 'QB Hurry_mean', \n",
      "     'Rec_mean', 'Rec TD_mean', 'Rec Yards_mean', 'Rush Att_mean', 'Rush TD_mean', 'Rush Yard_mean', \n",
      "     'Sack_mean', 'Sack Yard_mean', 'Safety_mean', 'Tackle Assist_mean', 'Tackle For Loss_mean', \n",
      "     'Tackle For Loss Yard_mean', 'Tackle Solo_mean']\n",
      "    \n",
      "    all_ncaa = all_ncaa.reindex_axis(col_order, axis=1)\n",
      "    all_ncaa.to_csv('data/ncaa.csv', sep=',')\n",
      "    print 'wrote to csv'\n",
      "    return all_ncaa\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scrapes and preprocesses NFL Combine data from http://nflcombineresults.com/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import pandas as pd\n",
      "# import string\n",
      "\n",
      "import requests\n",
      "from bs4 import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_combine_data():\n",
      "    '''Scrapes combine data for all years and returns a dataframe'''\n",
      "    combine = pd.DataFrame()\n",
      "    url = 'http://nflcombineresults.com/nflcombinedata.php?year=all&pos=&college='\n",
      "    r = requests.get(url)\n",
      "    soup = BeautifulSoup(r.content)\n",
      "    for tr in soup.find_all('tr')[1:-2]:        # to go into the table row-wise\n",
      "        playerstats = []                      \n",
      "        for td in tr.find_all('td'):            # to go into each column \n",
      "            playerstats.append(td.text)         # creates a list of each player's stats\n",
      "        combine = pd.concat((combine, pd.DataFrame(playerstats)), axis=1, ignore_index=True)\n",
      "    combine = combine.T\n",
      "    \n",
      "    # rename columns and standardize names\n",
      "    combine.columns = ['year_combine', 'name', 'college', 'position', 'height', 'weight', 'wonderlic', \n",
      "                       'forty_yard', 'bench_press', 'vertical_leap', 'broad_jump', 'shuttle', 'three_cone']\n",
      "    # clean up 'forty yard' feature and standardize name\n",
      "    table = string.maketrans(\"\",\"\")\n",
      "    combine['forty_yard'] = [float(str(d).replace('*','')) if d!='' else '' for d in combine['forty_yard']]\n",
      "    combine['first_name'] = [string.split(str(d.lower()).translate(table, string.punctuation), sep=' ')[0].strip() \n",
      "                             for d in combine.name]\n",
      "    combine['last_name'] = [string.split(str(d.lower()).translate(table, string.punctuation), sep=' ')[1].strip() \n",
      "                            for d in combine.name]\n",
      "    combine = combine.drop('name', axis=1)\n",
      "    \n",
      "    # drop combiners from 2005 or earlier\n",
      "    combine_year = combine.year_combine.astype(float)\n",
      "    ds = []\n",
      "    for d in combine.index:\n",
      "        if combine_year[d]<2006:\n",
      "            ds.append(d)\n",
      "    combine = combine.drop(ds)\n",
      "    combine.reset_index(inplace=True)\n",
      "    print \"Number of players in your dataset:\", combine.shape[0]\n",
      "\n",
      "    # reorder columns to put name up front, write to csv\n",
      "    cols = combine.columns.tolist()\n",
      "    cols = cols[-2:] + cols[:-2]\n",
      "    combine = combine[cols]\n",
      "    combine.to_csv('data/combine.csv', sep=',')\n",
      "    return combine\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scrapes and preprocesses NFL Draft data from http://www.drafthistory.com/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import pandas as pd\n",
      "# import string\n",
      "\n",
      "# import requests\n",
      "# from bs4 import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_draft_data():\n",
      "    '''Scrapes all draft history from 2006-2013 and returns a dataframe'''\n",
      "    seasons = arange(2006, 2014) # seasons 2006-2013\n",
      "    draft = pd.DataFrame()\n",
      "    for season in seasons:\n",
      "        url = 'http://www.drafthistory.com/index.php/years/'+str(season)\n",
      "        r = requests.get(url)\n",
      "        soup = BeautifulSoup(r.content)\n",
      "        for tr in soup.find_all('tr')[3:-9]:        # to go into the table row-wise\n",
      "            playerstats = []                      \n",
      "            for td in tr.find_all('td'):            # to go into each column \n",
      "                playerstats.append(td.text)         # creates a list of each player's stats\n",
      "            playerstats.append(season)                                \n",
      "            draft = pd.concat((draft, pd.DataFrame(playerstats)), axis=1, ignore_index=True)\n",
      "    print \"Number of players in your dataset:\", draft.shape[1]\n",
      "    draft = draft.T.drop(0,axis=1).drop(1,axis=1)\n",
      "    \n",
      "    # rename columns and standardize names\n",
      "    table = string.maketrans(\"\",\"\")\n",
      "    draft.columns = ['pick', 'name', 'team', 'position', 'college', 'year_drafted']\n",
      "    draft['first_name'] = [string.split(d.encode('ascii','ignore').lower().translate(table, string.punctuation),\n",
      "                                        sep=' ')[0].strip() for d in draft.name]\n",
      "    draft['last_name'] = [string.split(d.encode('ascii','ignore').lower().translate(table, string.punctuation), \n",
      "                                       sep=' ')[1].strip() for d in draft.name]\n",
      "    draft = draft.drop('name', axis=1)\n",
      "    \n",
      "    # reorder columns to put name up front, write to csv\n",
      "    cols = draft.columns.tolist()\n",
      "    cols = cols[-2:] + cols[:-2]\n",
      "    draft = draft[cols]\n",
      "    draft.to_csv('data/draft.csv', sep=',')\n",
      "    return draft\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scrapes and preprocesses NFL Fantasy Football data from http://fftoday.com/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import pandas as pd\n",
      "# import string\n",
      "\n",
      "# import requests\n",
      "# from bs4 import BeautifulSoup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_fantasy_data(position):\n",
      "    '''Scrapes fantasy data for the given position for seasons 2005 to 2014\n",
      "    Returns a dataframe'''\n",
      "    positions = {'QB':10, 'RB':20, 'WR':30, 'TE':40, 'DL':50, 'LB':60, 'DB':70, 'K':80}\n",
      "    pages = arange(0,5)          # top 250 fantasy scorers for the given position/season\n",
      "    seasons = arange(2005, 2014) # seasons 2005-2013\n",
      "    position_data = pd.DataFrame()\n",
      "    \n",
      "    for season in seasons:\n",
      "        for page in pages:\n",
      "            url = 'http://fftoday.com/stats/playerstats.php?Season='+str(season)+'&GameWeek=Season&PosID='+\\\n",
      "                  str(positions[position])+'&LeagueID=1&order_by=FFPts&sort_order=DESC&cur_page='+str(page)\n",
      "            r = requests.get(url)\n",
      "            soup = BeautifulSoup(r.content)\n",
      "            for tr in soup.find_all('tr')[20:-1]:                # to go into the table row-wise\n",
      "                playerstats = []                      \n",
      "                for td in tr.find_all('td'):                     # to go into each column \n",
      "                    playerstats.append(td.text.replace(',', '')) # creates a list of each player's stats\n",
      "                playerstats.append(season)\n",
      "                playerstats.append(position)\n",
      "                position_data = pd.concat((position_data, pd.DataFrame(playerstats)), axis=1, ignore_index=True)\n",
      "    position_data = position_data.T\n",
      "    position_data[0] = [string.replace(s.encode('ascii','ignore'),'. ','',maxreplace=1) for s in position_data[0]]\n",
      "    position_data[0] = [''.join(i for i in s if not i.isdigit()) for s in position_data[0]]\n",
      "    print \"Number of players in your dataset:\", position_data.shape[0]\n",
      "    return position_data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_floats(df):\n",
      "    cols = set(df.columns)\n",
      "    cols.remove('name')\n",
      "    cols.remove('team')\n",
      "    cols.remove('position')\n",
      "    df[list(cols)] = df[list(cols)].astype(float)\n",
      "    return df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_full_fantasy_data_set():\n",
      "    '''Builds full data set for all positions returns a dataframe'''\n",
      "    \n",
      "    first = ['name', 'team', 'games_played']\n",
      "    last =  ['ffpts', 'ffpts_gp', 'nfl_season', 'position']\n",
      "    #offense\n",
      "    qb = get_fantasy_data('QB')\n",
      "    qb.columns = first+['pass_comp', 'pass_att', 'pass_yd', 'pass_td', 'pass_int', \n",
      "                             'rush_att', 'rush_yd', 'rush_td']+last\n",
      "    qb = make_floats(qb)\n",
      "\n",
      "    rb = get_fantasy_data('RB')\n",
      "    rb.columns = first+['rush_att', 'rush_yd', 'rush_td', \n",
      "                        'rec_target', 'rec_reception', 'rec_yd', 'rec_td']+last\n",
      "    rb = make_floats(rb)\n",
      "    \n",
      "    wr = get_fantasy_data('WR')\n",
      "    wr.columns = first+['rec_target', 'rec_reception', 'rec_yd', 'rec_td',\n",
      "                        'rush_att', 'rush_yd', 'rush_td']+last\n",
      "    wr = make_floats(wr)\n",
      "    \n",
      "    te = get_fantasy_data('TE')\n",
      "    te.columns = first+['rec_target', 'rec_reception', 'rec_yd', 'rec_td']+last\n",
      "    te = make_floats(te)\n",
      "\n",
      "    ki = get_fantasy_data('K')\n",
      "    ki.columns = first+['fgm', 'fga', 'fg_perc', 'epm', 'epa']+last\n",
      "    ki = ki.drop('fg_perc', axis=1)\n",
      "    ki = make_floats(ki)\n",
      "\n",
      "    # defense\n",
      "    defense_cols = first+['tackle', 'assist', 'sack', 'pd', 'int', 'ff', 'fr']+last\n",
      "    dl = get_fantasy_data('DL')\n",
      "    dl.columns = defense_cols\n",
      "    dl = make_floats(dl)\n",
      "    \n",
      "    lb = get_fantasy_data('LB')\n",
      "    lb.columns = defense_cols\n",
      "    lb = make_floats(lb)\n",
      "    \n",
      "    db = get_fantasy_data('DB')\n",
      "    db.columns = defense_cols\n",
      "    db = make_floats(db)\n",
      "\n",
      "    # concatenate datasets\n",
      "    all_positions = pd.concat((qb, rb, wr, te, ki, dl, lb, db), ignore_index=True)\n",
      "    \n",
      "    # standardize names\n",
      "    table = string.maketrans(\"\",\"\")\n",
      "    all_positions['first_name'] = [string.split(d.lower().translate(table, string.punctuation), sep=' ')[0].strip() \n",
      "                              for d in all_positions.name]\n",
      "    all_positions['last_name'] = [string.split(d.lower().translate(table, string.punctuation), sep=' ')[1].strip() \n",
      "                             for d in all_positions.name]\n",
      "    all_positions = all_positions.drop('name', axis=1)\n",
      "    \n",
      "    # reorder columns\n",
      "    col_order = ['first_name', 'last_name', 'nfl_season', 'position', 'ffpts', 'team', 'games_played', 'ffpts_gp',\n",
      "     'pass_comp', 'pass_att', 'pass_yd', 'pass_td', 'pass_int',       # passing\n",
      "     'rush_att', 'rush_yd', 'rush_td',                                # rushing\n",
      "     'rec_target', 'rec_reception', 'rec_yd', 'rec_td',               # receiving\n",
      "     'fgm', 'fga', 'epm', 'epa',                                      # kicking\n",
      "     'tackle', 'assist', 'sack', 'pd', 'int', 'ff', 'fr']             # defending\n",
      "    all_positions = all_positions.reindex_axis(col_order, axis=1)\n",
      "    return all_positions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_rookies():\n",
      "    '''Builds data set for just rookies from 2006 and beyond\n",
      "    Returns a dataframe'''\n",
      "    df = build_full_fantasy_data_set()\n",
      "    \n",
      "    # group by player name and grab just their first three seasons\n",
      "    first_season = df.groupby(['last_name', 'first_name']).apply(\n",
      "        lambda t: t[t.nfl_season==t.nfl_season.min()])\n",
      "    second_season = df.groupby(['last_name', 'first_name']).apply(\n",
      "        lambda t: t[t.nfl_season==t.nfl_season.min()+1])\n",
      "    third_season = df.groupby(['last_name', 'first_name']).apply(\n",
      "        lambda t: t[t.nfl_season==t.nfl_season.min()+2])\n",
      "    \n",
      "    # remove anyone who's first season was in 2005\n",
      "    rookies = first_season[first_season.nfl_season > 2005]\n",
      "    rookies = pd.merge(rookies, second_season, how='left', on=['last_name', 'first_name'], suffixes=['', '_second'])\n",
      "    rookies = pd.merge(rookies, third_season,  how='left', on=['last_name', 'first_name'], suffixes=['', '_third'])\n",
      "    rookies.to_csv('data/rookies.csv', sep=',')\n",
      "    return rookies\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Joins fantasy, NCAA, NFL Combine, and NFL Draft datasets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import zipfile\n",
      "# import pandas as pd\n",
      "# import string\n",
      "\n",
      "# import requests\n",
      "# from bs4 import BeautifulSoup\n",
      "\n",
      "# import load_ncaa, scrape_combine, scrape_draft, scrape_fantasy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def standardize_college(col):\n",
      "    table = string.maketrans(\"\",\"\")\n",
      "    col = col.replace('USC', 'Southern California')\n",
      "    col = col.replace('Northwest Missouri St', 'Northwest Missouri State')\n",
      "    col = col.replace('Southeastern Louisiana', 'Southeast Louisiana')\n",
      "    col = col.replace('Missouri Southern State', 'Missouri Southern')\n",
      "    col = col.replace('LSU', 'Louisiana State')\n",
      "    col = col.replace('Tennessee-Chattanooga', 'Chattanooga')\n",
      "    col = col.replace('BYU', 'Brigham Young')\n",
      "    col = col.replace('TCU', 'Texas Christian')\n",
      "    col = col.replace('Stephen F Austin', 'Stephen F. Austin')\n",
      "    col = col.replace('Middle Tennessee St', 'Middle Tennessee State')\n",
      "    col = col.replace('Southern Miss', 'Southern Mississippi')\n",
      "    col = col.replace('Alabama St.', 'Alabama State')\n",
      "    col = col.replace('SMU', 'Southern Methodist')\n",
      "    col = col.replace('UAB', 'Alabama Birmingham')\n",
      "    col = col.replace('UNLV', 'Nevada Las Vegas')\n",
      "    col = col.replace('UTEP', 'Texas El Paso')\n",
      "    col = col.replace('UCF', 'Central Florida')\n",
      "\n",
      "    col = [string.split(str(d).lower(), ' (')[0].strip() for d in col]\n",
      "    col = [d.translate(table, string.punctuation).strip().replace(' ','') for d in col]\n",
      "    return col\n",
      "\n",
      "def standardize_names(col):\n",
      "    col = col.replace('pat', 'patrick').replace('ziggy', 'ezekial')\n",
      "    col = col.replace('erick', 'eric').replace('will', 'william')\n",
      "    col = col.replace('ballmer', 'balmer').replace('josh', 'joshua')\n",
      "    col = col.replace('johnathan', 'john').replace('herb', 'herbert')\n",
      "    col = col.replace('mike', 'michael').replace('chris', 'christopher')\n",
      "    col = col.replace('joe', 'joseph').replace('rob', 'robert')\n",
      "    col = col.replace('gabe', 'gabriel').replace('nate', 'nathan')\n",
      "    return col\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def merge_combine_and_draft():\n",
      "    '''Outer joins combine and draft data and returns a dataframe'''\n",
      "    \n",
      "    combine = get_combine_data()\n",
      "    draft = get_draft_data()\n",
      "\n",
      "    # standardize names of players and colleges\n",
      "    combine['college'] = standardize_college(combine['college'])\n",
      "    combine['first_name'] = standardize_names(combine['first_name'])\n",
      "    combine['last_name'] =  standardize_names(combine['last_name'])\n",
      "    \n",
      "    draft['college'] = standardize_college(draft['college'])\n",
      "    draft['first_name'] = standardize_names(draft['first_name'])\n",
      "    draft['last_name'] =  standardize_names(draft['last_name'])\n",
      "    \n",
      "    # outer join combine and draft\n",
      "    combine_and_draft = pd.merge(combine, draft, how='outer', suffixes=['_draft', '_combine'], \n",
      "                                 on=['last_name', 'first_name', 'college']).sort_index(\n",
      "                                 by=['last_name', 'first_name'], ascending=True)\n",
      "    combine_and_draft.reset_index(inplace=True)\n",
      "    print 'Number of players in merged dataset:', combine_and_draft.shape[0]\n",
      "    return combine_and_draft\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def merge_combine_draft_ncaa_and_fantasy():\n",
      "    '''Joins all four data sources and returns a dataframe'''\n",
      "    \n",
      "    combine_draft = merge_combine_and_draft()\n",
      "    ncaa = aggregate_stats()\n",
      "    fantasy = build_rookies()\n",
      "    \n",
      "    # standardize college and name\n",
      "    ncaa['college'] = standardize_college(ncaa['college'])\n",
      "    ncaa['first_name'] = standardize_names(ncaa['first_name'])\n",
      "    ncaa['last_name'] =  standardize_names(ncaa['last_name'])\n",
      "    \n",
      "    fantasy['first_name'] = standardize_names(fantasy['first_name'])\n",
      "    fantasy['last_name'] =  standardize_names(fantasy['last_name'])\n",
      "    \n",
      "    # outer join combine_draft with ncaa for comprehensive pre-NFL statistics\n",
      "    df = pd.merge(ncaa, combine_draft, how='outer', suffixes=['_ncaa', '_drcomb'], \n",
      "                       on=['last_name', 'first_name', 'college']).sort_index(\\\n",
      "                       by=['last_name', 'first_name'], ascending=True)\n",
      "    df.rename(columns={'Position':'position'}, inplace=True)\n",
      "    \n",
      "    # inner join combine_draft and ncaa with fantasy\n",
      "    df = pd.merge(fantasy, df, how='inner', suffixes=['_fantasy', '_prepro'], \n",
      "         on=['last_name', 'first_name']).sort_index(by=['last_name', 'first_name'], ascending=True)\n",
      "    # put name back together for convenience\n",
      "    df['name'] = [str(d[0])+' '+str(d[1]) for d in zip(df.first_name, df.last_name)]\n",
      "    df = df.drop(['first_name', 'last_name'], axis=1)\n",
      "    \n",
      "    print 'Number of players in final dataset:', df.shape[0]\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_up_data():\n",
      "    '''Builds up dataset, deletes duplicates, and reorders/renames columns\n",
      "    Returns a dataframe'''\n",
      "    \n",
      "    df = merge_combine_draft_ncaa_and_fantasy()\n",
      "\n",
      "    # deleting duplicate rows from mismatches\n",
      "    to_delete = [10, 11, 12, 13, 14, 35, 37, 43, 56, 57, 61, 70, 76, 121, 140, 141, \n",
      "         144, 156, 194, 221, 223, 225, 227, 228, 229, 230, 232, 237, 238, 240, \n",
      "         242, 245, 246, 250, 256, 257, 259, 260, 261, 262, 295, 313, 326, 327, \n",
      "         328, 329, 331, 332, 351, 363, 386, 400, 412, 413, 416, 417, 441, 450, \n",
      "         451, 459, 461, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 474, \n",
      "         478, 480, 481, 482, 484, 485, 487, 488, 490, 494, 496, 498, 499, 501, \n",
      "         549, 564, 569, 579, 586, 624, 625, 627, 635, 642, 649, 660, 673, 696, \n",
      "         697, 717, 719, 730, 747, 748, 758, 759, 764, 770, 771, 776, 777, 779, \n",
      "         783, 795, 807, 828, 830, 835, 837, 839, 840, 842, 846, 867, 870, 876, \n",
      "         881, 888, 893, 903, 918, 922, 923, 924, 925, 926, 928, 929, 936, 939, \n",
      "         945, 958, 963, 964, 978, 979, 984, 985, 986, 987, 988, 989, 991, 992, \n",
      "         993, 994, 995, 996, 1000, 1002, 1003, 1004, 1005, 1009, 1010, 1011, 1013, \n",
      "         1014, 1015, 1016, 1017, 1018, 1020, 1021, 1025, 1026, 1028, 1029, 1030, \n",
      "         1034, 1037, 1038, 1039, 1040, 1041, 1042, 1046, 1047, 1048, 1049, 1051, \n",
      "         1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, \n",
      "         1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, \n",
      "         1076, 1077, 1078, 1079, 1080, 1081, 1085, 1086, 1088, 1090, 1091, 1094, \n",
      "         1095, 1096, 1097, 1098, 1099, 1100, 1101, 1103, 1109, 1110, 1113, 1114, \n",
      "         1115, 1116, 1117, 1118, 1119, 1120, 1122, 1123, 1124, 1125, 1126, 1128, \n",
      "         1129, 1131, 1136, 1138, 1140, 1141, 1142, 1144, 1146, 1147, 1148, 1151, \n",
      "         1152, 1153, 1155, 1156, 1186, 1188, 1190, 1228, 1229, 1248, 1256, 1258, \n",
      "         1259, 1311, 1317, 1321, 1322, 1325, 1338, 1375, 1396, 1420, 1424, 1428, \n",
      "         1429, 1434, 1435, 1436, 1437, 1438, 1447, 1452, 1453, 1462, 1464, 1476, \n",
      "         1481, 1483, 1488, 1521, 1538, 1552, 1570, 1572, 1573, 1586, 1587, 1592, \n",
      "         1609, 1612, 1619, 1632, 1649, 1654, 1657, 1689, 1703, 1705, 1725, 1727, \n",
      "         1728, 1731, 1734, 1743, 1745, 1799, 1828, 1838, 1846, 1847, 1849, 1851, \n",
      "         1853, 1858, 1860, 1861, 1863, 1866, 1867, 1868, 1869, 1870, 1872, 1873, \n",
      "         1876, 1877, 1878, 1879, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1890, \n",
      "         1898, 1928, 1930, 1931, 1933, 1970, 1973, 1979, 1980, 1981, 1990, 1992, \n",
      "         1994, 1997, 1999, 2003, 2004, 2005, 2007, 2008, 2009, 2010, 2011, 2012, \n",
      "         2013, 2015, 2020, 2022, 2023, 2024, 2026, 2028, 2031, 2081, 2084, 2088, \n",
      "         2105, 2127, 2129, 2130, 2131, 2132, 2133, 2137, 2139, 2153, 2154, 2155, \n",
      "         2156, 2157, 2159, 2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, \n",
      "         2170, 2171, 2172, 2175, 2178, 2182, 2183, 2185, 2187, 2191, 2192, 2193, \n",
      "         2194, 2198, 2200, 2202, 2203, 2204, 2209, 2210, 2211, 2212, 2213, 2214, \n",
      "         2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2228, 2229, 2231, 2235, \n",
      "         2239, 2240, 2241, 2242, 2244, 2246, 2247, 2248, 2250, 2258, 2259, 2261, \n",
      "         2273, 2278, 2285]\n",
      "    df = df.drop(to_delete)\n",
      "\n",
      "    # selecting columns\n",
      "    cols = ['name', \n",
      "        'nfl_season', 'position_fantasy', 'ffpts', 'ffpts_gp', 'team_fantasy', 'games_played',\n",
      "        'pass_comp', 'pass_att', 'pass_yd', 'pass_td', 'pass_int', \n",
      "        'rush_att', 'rush_yd', 'rush_td', \n",
      "        'rec_target', 'rec_reception', 'rec_yd', 'rec_td', \n",
      "        'fgm', 'fga', 'epm', 'epa', 'tackle', 'assist', \n",
      "        'sack', 'pd', 'int', 'ff', 'fr', \n",
      "        \n",
      "        'nfl_season_second', 'position_second', 'ffpts_second', 'team_second', 'games_played_second', 'ffpts_gp_second', \n",
      "        'pass_comp_second', 'pass_att_second', 'pass_yd_second', 'pass_td_second', 'pass_int_second', \n",
      "        'rush_att_second', 'rush_yd_second', 'rush_td_second', \n",
      "        'rec_target_second', 'rec_reception_second', 'rec_yd_second', 'rec_td_second', \n",
      "        'fgm_second', 'fga_second', 'epm_second', 'epa_second', 'tackle_second', 'assist_second', \n",
      "        'sack_second', 'pd_second', 'int_second', 'ff_second', 'fr_second', \n",
      "        \n",
      "        'nfl_season_third', 'position_third', 'ffpts_third', 'team_third', 'games_played_third', 'ffpts_gp_third', \n",
      "        'pass_comp_third', 'pass_att_third', 'pass_yd_third', 'pass_td_third', 'pass_int_third', \n",
      "        'rush_att_third', 'rush_yd_third', 'rush_td_third', \n",
      "        'rec_target_third', 'rec_reception_third', 'rec_yd_third', 'rec_td_third', \n",
      "        'fgm_third', 'fga_third', 'epm_third', 'epa_third', 'tackle_third', 'assist_third', \n",
      "        'sack_third', 'pd_third', 'int_third', 'ff_third', 'fr_third', \n",
      "        \n",
      "        'pick', 'height', 'weight', 'wonderlic', 'forty_yard', 'bench_press', 'vertical_leap', 'broad_jump', \n",
      "        'shuttle', 'three_cone', \n",
      "        \n",
      "        'Pass Att_sum', 'Pass Comp_sum', 'Pass Conv_sum', 'Pass Int_sum', 'Pass TD_sum', 'Pass Yard_sum', \n",
      "        'QB Hurry_sum', 'Rec_sum', 'Rec TD_sum', 'Rec Yards_sum', \n",
      "        'Rush Att_sum', 'Rush TD_sum', 'Rush Yard_sum', 'Fumble_sum', 'Fumble Lost_sum', \n",
      "        'Kickoff Ret_sum', 'Kickoff Ret TD_sum', 'Kickoff Ret Yard_sum', 'Kickoff Touchback_sum', \n",
      "        'Punt Ret_sum', 'Punt Ret TD_sum', 'Punt Ret Yard_sum', 'Off 2XP Att_sum', 'Off 2XP Made_sum', \n",
      "        'Points_sum', 'Tackle Assist_sum', 'Tackle For Loss_sum', 'Tackle For Loss Yard_sum', 'Tackle Solo_sum', \n",
      "        'Pass Broken Up_sum', 'Sack_sum', 'Sack Yard_sum', \n",
      "        'Int Ret_sum', 'Int Ret TD_sum', 'Int Ret Yard_sum', \n",
      "        'Misc Ret_sum', 'Misc Ret TD_sum', 'Misc Ret Yard_sum', 'Kick/Punt Blocked_sum', \n",
      "        'Fumble Forced_sum', 'Fum Ret_sum', 'Fum Ret TD_sum', 'Fum Ret Yard_sum', \n",
      "        'Def 2XP Att_sum', 'Def 2XP Made_sum', 'Safety_sum', \n",
      "        'Field Goal Att_sum', 'Field Goal Made_sum', 'Off XP Kick Att_sum', 'Off XP Kick Made_sum', \n",
      "        'Punt_sum', 'Punt Yard_sum', 'Kickoff_sum', 'Kickoff Yard_sum', \n",
      "        'Kickoff Onside_sum', 'Kickoff Out-Of-Bounds_sum',\n",
      "        \n",
      "        'Pass Att_mean', 'Pass Comp_mean', 'Pass Conv_mean', 'Pass Int_mean', 'Pass TD_mean', 'Pass Yard_mean', \n",
      "        'QB Hurry_mean', 'Rec_mean', 'Rec TD_mean', 'Rec Yards_mean', \n",
      "        'Rush Att_mean', 'Rush TD_mean', 'Rush Yard_mean', 'Fumble_mean', 'Fumble Lost_mean', \n",
      "        'Kickoff Ret_mean', 'Kickoff Ret TD_mean', 'Kickoff Ret Yard_mean', 'Kickoff Touchback_mean', \n",
      "        'Punt Ret_mean', 'Punt Ret TD_mean', 'Punt Ret Yard_mean', 'Off 2XP Att_mean', 'Off 2XP Made_mean', \n",
      "        'Points_mean', 'Tackle Assist_mean', 'Tackle For Loss_mean', 'Tackle For Loss Yard_mean', 'Tackle Solo_mean', \n",
      "        'Pass Broken Up_mean', 'Sack_mean', 'Sack Yard_mean', \n",
      "        'Int Ret_mean', 'Int Ret TD_mean', 'Int Ret Yard_mean', \n",
      "        'Misc Ret_mean', 'Misc Ret TD_mean', 'Misc Ret Yard_mean', 'Kick/Punt Blocked_mean', \n",
      "        'Fumble Forced_mean', 'Fum Ret_mean', 'Fum Ret TD_mean', 'Fum Ret Yard_mean', \n",
      "        'Def 2XP Att_mean', 'Def 2XP Made_mean', 'Safety_mean', \n",
      "        'Field Goal Att_mean', 'Field Goal Made_mean', 'Off XP Kick Att_mean', 'Off XP Kick Made_mean', \n",
      "        'Punt_mean', 'Punt Yard_mean', 'Kickoff_mean', 'Kickoff Yard_mean', \n",
      "        'Kickoff Onside_mean', 'Kickoff Out-Of-Bounds_mean',\n",
      "        \n",
      "        'Class', 'college', 'conference', 'subn', \n",
      "        'Height', 'Weight', 'Home Country', 'Home State', 'Home Town', 'Last School',]\n",
      "    df = df[cols]\n",
      "    \n",
      "    # reordering columns\n",
      "    # fantasy\n",
      "    rookie = ['nfl_season', 'position', 'ffpts', 'ffpts_gp', 'team', 'games_played',\n",
      "        'pass_comp', 'pass_att', 'pass_yd', 'pass_td', 'pass_int', \n",
      "        'rush_att', 'rush_yd', 'rush_td', \n",
      "        'rec_target', 'rec_reception', 'rec_yd', 'rec_td', \n",
      "        'fgm', 'fga', 'epm', 'epa', 'tackle', 'assist', \n",
      "        'sack', 'pd', 'int', 'ff', 'fr']  \n",
      "    second = ['nfl_season_second', 'position_second', 'ffpts_second', 'team_second', 'games_played_second', 'ffpts_gp_second', \n",
      "        'pass_comp_second', 'pass_att_second', 'pass_yd_second', 'pass_td_second', 'pass_int_second', \n",
      "        'rush_att_second', 'rush_yd_second', 'rush_td_second', \n",
      "        'rec_target_second', 'rec_reception_second', 'rec_yd_second', 'rec_td_second', \n",
      "        'fgm_second', 'fga_second', 'epm_second', 'epa_second', 'tackle_second', 'assist_second', \n",
      "        'sack_second', 'pd_second', 'int_second', 'ff_second', 'fr_second'] \n",
      "    third = ['nfl_season_third', 'position_third', 'ffpts_third', 'team_third', 'games_played_third', 'ffpts_gp_third', \n",
      "        'pass_comp_third', 'pass_att_third', 'pass_yd_third', 'pass_td_third', 'pass_int_third', \n",
      "        'rush_att_third', 'rush_yd_third', 'rush_td_third', \n",
      "        'rec_target_third', 'rec_reception_third', 'rec_yd_third', 'rec_td_third', \n",
      "        'fgm_third', 'fga_third', 'epm_third', 'epa_third', 'tackle_third', 'assist_third', \n",
      "        'sack_third', 'pd_third', 'int_third', 'ff_third', 'fr_third']\n",
      "    # draft and combine\n",
      "    draft_combine = ['draft_pick', 'height_combine', 'weight_combine', 'wonderlic', 'forty_yard', \n",
      "        'bench_press', 'vertical_leap', 'broad_jump', 'shuttle', 'three_cone']\n",
      "    # ncaa\n",
      "    ncaa_sum = ['Pass Att_sum', 'Pass Comp_sum', 'Pass Conv_sum', 'Pass Int_sum', 'Pass TD_sum', 'Pass Yard_sum', \n",
      "        'QB Hurry_sum', 'Rec_sum', 'Rec TD_sum', 'Rec Yards_sum', \n",
      "        'Rush Att_sum', 'Rush TD_sum', 'Rush Yard_sum', 'Fumble_sum', 'Fumble Lost_sum', \n",
      "        'Kickoff Ret_sum', 'Kickoff Ret TD_sum', 'Kickoff Ret Yard_sum', 'Kickoff Touchback_sum', \n",
      "        'Punt Ret_sum', 'Punt Ret TD_sum', 'Punt Ret Yard_sum', 'Off 2XP Att_sum', 'Off 2XP Made_sum', \n",
      "        'Points_sum', 'Tackle Assist_sum', 'Tackle For Loss_sum', 'Tackle For Loss Yard_sum', 'Tackle Solo_sum', \n",
      "        'Pass Broken Up_sum', 'Sack_sum', 'Sack Yard_sum', \n",
      "        'Int Ret_sum', 'Int Ret TD_sum', 'Int Ret Yard_sum', \n",
      "        'Misc Ret_sum', 'Misc Ret TD_sum', 'Misc Ret Yard_sum', 'Kick/Punt Blocked_sum', \n",
      "        'Fumble Forced_sum', 'Fum Ret_sum', 'Fum Ret TD_sum', 'Fum Ret Yard_sum', \n",
      "        'Def 2XP Att_sum', 'Def 2XP Made_sum', 'Safety_sum', \n",
      "        'Field Goal Att_sum', 'Field Goal Made_sum', 'Off XP Kick Att_sum', 'Off XP Kick Made_sum', \n",
      "        'Punt_sum', 'Punt Yard_sum', 'Kickoff_sum', 'Kickoff Yard_sum', \n",
      "        'Kickoff Onside_sum', 'Kickoff Out-Of-Bounds_sum']\n",
      "    ncaa_mean = ['Pass Att_mean', 'Pass Comp_mean', 'Pass Conv_mean', 'Pass Int_mean', 'Pass TD_mean', 'Pass Yard_mean', \n",
      "        'QB Hurry_mean', 'Rec_mean', 'Rec TD_mean', 'Rec Yards_mean', \n",
      "        'Rush Att_mean', 'Rush TD_mean', 'Rush Yard_mean', 'Fumble_mean', 'Fumble Lost_mean', \n",
      "        'Kickoff Ret_mean', 'Kickoff Ret TD_mean', 'Kickoff Ret Yard_mean', 'Kickoff Touchback_mean', \n",
      "        'Punt Ret_mean', 'Punt Ret TD_mean', 'Punt Ret Yard_mean', 'Off 2XP Att_mean', 'Off 2XP Made_mean', \n",
      "        'Points_mean', 'Tackle Assist_mean', 'Tackle For Loss_mean', 'Tackle For Loss Yard_mean', 'Tackle Solo_mean', \n",
      "        'Pass Broken Up_mean', 'Sack_mean', 'Sack Yard_mean', \n",
      "        'Int Ret_mean', 'Int Ret TD_mean', 'Int Ret Yard_mean', \n",
      "        'Misc Ret_mean', 'Misc Ret TD_mean', 'Misc Ret Yard_mean', 'Kick/Punt Blocked_mean', \n",
      "        'Fumble Forced_mean', 'Fum Ret_mean', 'Fum Ret TD_mean', 'Fum Ret Yard_mean', \n",
      "        'Def 2XP Att_mean', 'Def 2XP Made_mean', 'Safety_mean', \n",
      "        'Field Goal Att_mean', 'Field Goal Made_mean', 'Off XP Kick Att_mean', 'Off XP Kick Made_mean', \n",
      "        'Punt_mean', 'Punt Yard_mean', 'Kickoff_mean', 'Kickoff Yard_mean', \n",
      "        'Kickoff Onside_mean', 'Kickoff Out-Of-Bounds_mean']\n",
      "    basics = ['class', 'college', 'conference', 'subn', \n",
      "        'height_ncaa', 'weight_ncaa', 'Home Country', 'Home State', 'Home Town', 'Last School',]\n",
      "    \n",
      "    colnames = [['name']+rookie+second+third+draft_combine+ncaa_sum+ncaa_mean+basics]\n",
      "    df.columns = colnames\n",
      "    df.to_csv('data/all_data.csv', sep=',')\n",
      "    print 'Number of clean players in final dataset:', df.shape[0]\n",
      "    return df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "start = time.time()\n",
      "foo = clean_up_data()\n",
      "print 'time in minutes', (time.time()-start)/60"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of players in your dataset: 2615\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2034\n",
        "Number of players in merged dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3107\n",
        "2013-1.5.20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (21794, 14)\n",
        "2013-1.5.20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (60583, 59)\n",
        "2012-1.5.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (21229, 14)\n",
        "2012-1.5.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (59286, 59)\n",
        "2011-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (20698, 14)\n",
        "2011-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (57817, 59)\n",
        "2010-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (20123, 14)\n",
        "2010-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (57327, 59)\n",
        "2009-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (20195, 14)\n",
        "2009-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (56915, 59)\n",
        "2008-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (19226, 14)\n",
        "2008-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (55196, 59)\n",
        "2007-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (18343, 14)\n",
        "2007-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (54912, 59)\n",
        "2006-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (17753, 14)\n",
        "2006-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (52513, 59)\n",
        "2005-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (22879, 14)\n",
        "2005-1.5.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (49257, 59)\n",
        "built dataframes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "grouped players"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "aggregated stats"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "wrote to csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 715\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1524\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1765\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1002\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 345\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2249\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2231\n",
        "Number of players in your dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2250\n",
        "Number of players in final dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2312\n",
        "Number of clean players in final dataset:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1840\n",
        "time in minutes 6.24582064946\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}